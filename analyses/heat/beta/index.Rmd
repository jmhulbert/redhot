---
title: "Beta Distribution Response to Urban Heat"
author: "Joey Hulbert"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
    toc_depth: 3
---


|            |            |            |            |
|:----------:|:----------:|:----------:|:----------:|
|[Welcome](https://jmhulbert.github.io/redhot)|[Data](https://jmhulbert.github.io/redhot/data)|[Analyses](https://jmhulbert.github.io/redhot/analyses)|[Discussion](https://jmhulbert.github.io/redhot/discussion)|
|             |           |            |            |


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(corrplot)
library(knitr)
library(kableExtra)
library(gghalves)
library(patchwork)
library(scales)
library(glmmTMB)
library(bbmle)
library(DHARMa)
```


# Purpose

The purpose of this page is to summarize an investigation of **percent (proportion) canopy dieback** as a *continuous* response to urban heat (temperatures).

# Read Data

```{r}
data <- read.csv('https://raw.githubusercontent.com/jmhulbert/redhot/main/data/urban-data-modified.csv')
```

# Notes


* **Summary**
    + Percent Dieback Percent for `r nrow(data[data$user.estimated.dieback=="No", ])` observations were categorized input (percent canopy dieback 1-29% as 1 -- see below)
    + Dead trees are removed

### Convert categorical to continuous 

Not all observations had a continuous value of percent canopy dieback estimated by the user. In retrospec, we should have required this question, but instead, we had a categorical question. 

Therefore, we converted the categorical answers to continuous data (possibly shady - we know, which is why we also completed an [ordinal analysis](https://jmhulbert.github.io/redhot/analyses/heat/ordinal/)) in the [Data](https://jmhulbert.github.io/redhot/data). 

It makes it messy, but we may want to redo this analysis with only the `r nrow(data[data$user.estimated.dieback=="Yes", ])` observations with user estimated percent canopy dieback to look at effects of heat on trees with dieback or to see if it influences whether there was any dieback at all. 

```{r}
#data$Percent.Dieback.Modified[data$field.percent.canopy.affected....=="Healthy, no dieback(0%)"] <- 0
#data$Percent.Dieback.Modified[data$field.percent.canopy.affected....=="1-29% of the canopy is unhealthy"] <- 1
#data$Percent.Dieback.Modified[data$field.percent.canopy.affected....=="30-59% of the canopy is unhealthy"] <- 30
#data$Percent.Dieback.Modified[data$field.percent.canopy.affected....=="60-99% of the canopy is unhealthy"] <- 60
#data$Percent.Dieback.Modified[data$field.percent.canopy.affected....=="tree is dead"] <- 100
#data$field.dieback.percent[is.na(data$field.dieback.percent)] <- data$Percent.Dieback.Modified
```

### Remove dead Trees
  
Beta distributions model proportions between 0 and 1. Therefore, we removed dead trees (100% dieback = 1)
  
> zibeta.daily <- glmmTMB(field.dieback.prop~DN_AF1 + (1|Area),data=data,ziformula=~1,family=beta_family())

For example, the above model threw the following error because we had dead trees with proportions of 1.0. 

> Error in eval(family$initialize) : y values must be 0 <= y < 1

An alternative way around would be to change 1s to .99 as suggested by Ben Bolker [here](https://github.com/glmmTMB/glmmTMB/issues/507). However, another option, as noted in the [GLMM FAQ (Beta GLMMs section)](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#beta-glmms) is to use the brms package because it can handle zero-one inflated models. 

However, given we're not sure if why they died, it may be most biologically relevant to remove the dead trees from the analysis. 

Dead trees were excluded from below models


```{r}
# Remove Dead Trees
data.w.dead <- data 
data <- data %>% filter(field.tree.canopy.symptoms!="Tree is dead") %>% filter(field.dieback.percent<100) %>% droplevels()
```

* Additional questions
  + Should we include random effect in zi formula?
    + It is [apparently possible](https://stats.stackexchange.com/questions/604045/glmmtmb-random-effects-on-zero-inflation-component), but adds model complexity and generally needs large data sets

# Analysis

**Does tree dieback (proportion/percent dieback) increase with increases in urban heat?**

## Fit models

```{r}
#data <- data %>% filter(dist.from.mean.daily!="NA") #drops one observation that was causing issue in model summary
```


```{r}
zibeta.daily <- glmmTMB(field.dieback.prop~ dist.from.mean.daily + (1|Area),data=data,ziformula=~dist.from.mean.daily,family=beta_family())
zibeta.am <- glmmTMB(field.dieback.prop~ dist.from.mean.am + (1|Area),data=data,ziformula=~dist.from.mean.am,family=beta_family())
zibeta.af <- glmmTMB(field.dieback.prop~ dist.from.mean.af + (1|Area),data=data,ziformula=~dist.from.mean.af,family=beta_family())
zibeta.pm <- glmmTMB(field.dieback.prop~ dist.from.mean.pm + (1|Area),data=data,ziformula=~dist.from.mean.pm,family=beta_family())
```

## Compare models

```{r}
AICtab(zibeta.daily,zibeta.am,zibeta.af,zibeta.pm)
```

Lowest score is most preferred model. Difference in AIC scores can be intrepreted as 'extra information lost' by using the worse model in comparison to the better model. 

The model with AF temperatures was the best fit. 

## Summarize Best Model

```{r}
summary(zibeta.af)
```

The conditional output is indicating that for all observations with greater than 0 dieback proportions, distance from mean am influences the proprtion of dieback. The zi model tells us which predictor increases the propability of non-zero.

> interesting that the distance from mean am has a negative estimate though - hard to know if it is observations higher than the mean or lower than the mean (ie as temp increases, distance from mean decreases (but higher or lower than mean))


## Model Diagnostics

```{r}
hist(residuals(zibeta.af))
```

```{r}
simulationOutput <- simulateResiduals(zibeta.af)
plot(simulationOutput)
```

Residuals are differences between our observed values and those predicted by the model. 

Quantile deviations refers to differences in observed residuals vs expected residuals of the model (e.g. residuals are not following normal distribution). 

Simulated residuals are calculated from a number of similations using fitted model for diagnostics.

* Interpreting 'Quantile Deviations Detected':
  + Distribution of residuals doesn't match the expected distribution.
  + Possible: model misspecification, such as the wrong distribution, too many outliers, or a need transformation of the response variable.
  + May also suggest important predictors are missing, or that the variance structure of the model is not correctly specified.

### Confirm model is zero inflated

```{r}
testZeroInflation(simulationOutput)
```

The zero count is not significantly higher than expected. Perhaps zero inflation is not needed. 


# Interpretation

The model is likely not appropriate, especially given the (shady?) conversion of a categorical variable to a continuous variable, but it may generally indicates temperature is relevant for predicting proportion dieback, at least with trees that have some dieback.  

# Next steps

Possibly compare fit of a model with and without zero inflation? 


```{r}
#beta.af <- glmmTMB(field.dieback.prop~ dist.from.mean.af + (1|Area),data=data,family=beta_family())
```

Oh yes, this throws an error? Would need to remove zeros? 

Only useful for testing if dieback is related to urban heat if there is some diback to begin with? 

```{r}
#AICtab(zibeta.af,beta.af)
```



Repeat, but modify approach, to use the `r nrow(data[data$user.estimated.dieback=="Yes", ])` observations with user estimated percent canopy dieback.



--







